{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "### 1.1 Scenario\n",
    "Now, as the watch industry transforms with the likes of Apple and Fitbit entering the technology and SmartWatch space and other new brands entering through e-commerce and social media like Daniel Wellington. Guess needs to do some rapid changes to their business to ensure guess watches remain a dominant player for the future.\n",
    "\n",
    "Their social media presence and running an event over here in the United States. The question they have is the following guess watches is planning on hosting an event in New York City where there will launch a new collection in conjunction with a New York-based social-media influencer. She's a millennial fashion and lifestyle influencer who became famous through her blog and later Instagram. Those attending the event will be other smaller social media influences as well as press the goal of the game is to create buzz and awareness via social media about the new collaboration with their target demographic of females primarily aged 18 to 30.\n",
    "\n",
    "Guess wants you to recommend the following. Guess would like to know a specific location where Guess should have the event, and this can be any of the five boroughs of New York. They would like to know the best way to find other smaller social media influencers to invite to the event and what the criteria are for choosing them. They also want to know the best digital and social channels to focus on leading up and throughout the event to reach their target audience and ensure interest and exposure.\n",
    "\n",
    "### 1.2  Interpretation\n",
    "After reading this scenario, we all know we have 3 main tasks.\n",
    "\n",
    "1. Find the best one of five boroughs in New York for the new collection event.\n",
    "\n",
    "2. Find the best way to know those smaller influencers should be invited.\n",
    "\n",
    "3. Find the best digital channel to promote this event and products efficiently and effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.What is Guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Guess Stoty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUESS was established in 1981 by the Marciano brothers, who left the south of France in pursuit of the American dream. Inspired by a European influence, the Marcianos redefined denim. One of their initial designs was a stonewashed, slim-fitting jean, the 3-zip Marilyn. Bloomingdale's was the first department store to welcome the brand by ordering two dozen pairs of jeans. They disappeared from the shelves in just hours. [1]\n",
    "\n",
    "GUESS quickly became a symbol of a young, sexy and adventurous lifestyle. Throughout the decades GUESS invited people to dream with its iconic and timeless advertising campaigns that turned unknown faces into famous models.\n",
    "\n",
    "In 1984 Guess introduced its new line of watches known as \"Guess\", \"Guess Steel\", and the \"Guess Collection\" The watch line is still in existence today, and has been joined by a number of other accessory sidelines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The audience of Guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our tasks are to help Guess attract more customers, the first step is to know who should be the target audience of Guess. \n",
    "\n",
    "Christopher Palmeri provides descriptions of the consumer. \"The Guess girl is edgy, sexy, confident,\" he says. \"And she loves to be looked at.\" Guess has had females like Paris Hilton model for them. She is within the range of the target market that they are trying to sell to.\n",
    "\n",
    "Demographically, these three markets can look very different and the same. They can be of various nationalities, races, religions, family sizes, ages, and from different locations. Generally, I think their income is similar; upper-middle class and up. Consumers in the same demographic groups can be very different psychographically. Psychographics are based on a social level, lifestyles, and personality characteristics. The psychographics of the Guess target markets should be that they are <b>middle to upper class</b> because they have very social lifestyles, are adventurous, sexy, and stylish.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Where should be chosen for event?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the target audience is from middle to upper class. Based on this, we hope the borough has enough population to support this event. At the same time, the people should be wealthy, and they belong to the middle to upper class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get the information of five boroughs in New York "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install html5lib\n",
    "!pip install bs4\n",
    "!pip install html5lib\n",
    "!pip install -e git+https://github.com/LevPasha/Instagram-API-python.git#egg=InstagramAPI\n",
    "!pip install InstagramApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Basic information about New York</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for dataframes and matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "# Set variables for file and index column\n",
    "file = 'population_newyork.csv' #see above\n",
    "colname = 'Borough' #open the csv and have a look\n",
    "\n",
    "# Read in the percent of gdp data\n",
    "population = pandas.read_csv(file, index_col= colname)\n",
    "print(population.shape)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Population visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get population  data of New York\n",
    "filter_stand =['Population (2017)']\n",
    "\n",
    "populationOfNewYork = population.filter(filter_stand, axis=1)\n",
    "\n",
    "populationOfFive = populationOfNewYork.loc['The Bronx':'Staten Island','Population (2017)']\n",
    "print('The density of five boroughs')\n",
    "print(populationOfFive)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#Get population density data of New York\n",
    "filter_stand =['persons/sq. km']\n",
    "populationDensityOfNewYork = population.filter(filter_stand, axis=1)\n",
    "populationDensityOfFive = populationDensityOfNewYork.loc['The Bronx':'Staten Island','persons/sq. km']\n",
    "print('The density of five boroughs')\n",
    "print(populationDensityOfFive)\n",
    "print('\\n')\n",
    "\n",
    "#Get the GDP of New York\n",
    "filter_stand =['per capita (US$)']\n",
    "GDPOfNewYork = population.filter(filter_stand, axis=1)\n",
    "GDPOfFive = GDPOfNewYork.loc['The Bronx':'Staten Island','per capita (US$)']\n",
    "print('The personal average GDP of five boroughs')\n",
    "print(GDPOfFive)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Setup the data\n",
    "\n",
    "x = [\"Borough\",\"Brooklyn\",\"Manhattan\",\"Queens\",\"Staten Island\"]\n",
    "colours = ['red','green','pink','yellow','blue']\n",
    "#Plot the data\n",
    "plt.bar(x,populationOfFive, color=colours)\n",
    "\n",
    "#Lable the chart\n",
    "plt.ylabel('population')\n",
    "plt.xlabel('city')\n",
    "plt.title('Pupulation of five boroughs in New York')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Visualization, we can know <b>Brooklyn</b> has the most population. Queens is on the second place and Manhattan is on the third place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pupulation Density Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x,populationDensityOfFive, color=colours)\n",
    "\n",
    "#Lable the chart\n",
    "plt.ylabel('population')\n",
    "plt.xlabel('city')\n",
    "plt.title('Pupulation Density of five boroughs in New York')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Visualization, we can know <b>Manhattan</b> has the most population density. It means it is much easier to spread during people than other boroughs when something happened. People gather together much quickly in Manhattan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Average GDP  Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x,GDPOfFive, color=colours)\n",
    "\n",
    "#Lable the chart\n",
    "plt.ylabel('per capita (US$)')\n",
    "plt.xlabel('city')\n",
    "plt.title(' Personal average GDP of five boroughs in New York')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Visualization, we can know <b>Manhattan</b> has a much higher average GDP the other places. It means the most rich and middle and upper-class people live here. Those people are the target audience of Guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Boroughs Reputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want more people can focus on the event, the reputation of the place is also crucial. If the boroughs have an excellent reputation, it will attract more people coming. So we are going to analyse people attitudes to these five boroughs on Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tweepy           # To access and consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "# Twitter App access keys\n",
    "\n",
    "# Consume:\n",
    "CONSUMER_KEY    = 'kqboNqw0Wid2C2Hq5SjkMgAnL'\n",
    "CONSUMER_SECRET = '6f9lnniVRW0fAO9qnmWeVrueJvzbMW6omWcIEssyWfHtLBVgqx'\n",
    "\n",
    "# Access:\n",
    "ACCESS_TOKEN  = '1109325911944421377-zKKyOUVCvZQszex0gFBfjTNgoCtBey'\n",
    "ACCESS_SECRET = 'NOnVAYOmDpa1WRD3qfgx1rYH2CjCdKecGJ6ILXUW9goyI'\n",
    "\n",
    "# API's setup:\n",
    "def connectToTwitterAPI():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with access keys.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extractor object\n",
    "extractor = connectToTwitterAPI()\n",
    "\n",
    "# Specify search criteria and extract tweets into a list\n",
    "tweets = extractor.search(q=\"#Manhattan\", lang = \"en\", count=1000)\n",
    "\n",
    "# Print the total number of extracted tweets\n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pandas dataframe\n",
    "data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "\n",
    "# Add relavant data from each tweet\n",
    "data['len']  = np.array([len(tweet.text) for tweet in tweets]) #textual content legnth\n",
    "data['ID']   = np.array([tweet.id for tweet in tweets])\n",
    "data['Date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "data['Source'] = np.array([tweet.source for tweet in tweets])\n",
    "data['Likes']  = np.array([tweet.favorite_count for tweet in tweets]) #likes counts\n",
    "data['RTs']    = np.array([tweet.retweet_count for tweet in tweets]) #retweets count\n",
    "\n",
    "# Display the first 10 elements of the dataframe\n",
    "display(data.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def cleanTweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyseSentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(cleanTweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentiment for each tweet and add the result into a new column\n",
    "data['Sentiment'] = np.array([ analyseSentiment(tweet) for tweet in data['Tweets'] ])\n",
    "\n",
    "# Display the first 10 elements of the dataframe\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lists with classified tweets\n",
    "\n",
    "positiveTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['Sentiment'][index] > 0]\n",
    "neutralTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['Sentiment'][index] == 0]\n",
    "negativeTweets = [ tweet for index, tweet in enumerate(data['Tweets']) if data['Sentiment'][index] < 0]\n",
    "\n",
    "# Calculate percentages\n",
    "\n",
    "positivePercent = len(positiveTweets)*100/len(data['Tweets'])\n",
    "neutralPercent = len(neutralTweets)*100/len(data['Tweets'])\n",
    "negativePercent = len(negativeTweets)*100/len(data['Tweets'])\n",
    "\n",
    "# Print percentages\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(positivePercent))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(neutralPercent))\n",
    "print(\"Percentage de negative tweets: {}%\".format(negativePercent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting and visualization\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "labels = ['Positive', 'Neutral', 'Negative']\n",
    "sizes = [positivePercent, neutralPercent, negativePercent]\n",
    "\n",
    "# Set different colors\n",
    "colors = ['green', 'grey', 'red']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After input five boroughs many times, we found that <b>Manhattan</b> always has the lowest negative percentage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider three elements above, we choose <b>Manhattan as the best place</b> for holding the event because Guess customers are over there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Who should be invited?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who should be invited? I think this is the most important part in this task because these influencers can create internet buzz easily. Unlike traditional top-down advertising campaigns, Instagram influencers can speak to their audiences as trusted peers, inspiring the kind of authentic word-of-mouth engagement that turns viewers into loyal customers. With consumers becoming savvier than ever, Instagram influencers will be crucial to driving sales.   \n",
    "\n",
    "<b>The first question</b>is which area Instagram influencers should we invite. About fashion? About the design? Alternatively, about others. In our opinion, it depends on the product Guess they sell and what the selling point. As a watch, Guess can invite watch influencers. As a well-designed artefact, they can ask great designers on Instagram to attend the event. As a fashionable accessory, they can invite those fashion & style Influencers on Instagram.  <b>Here we consider Guess watches are more like a colourful and fashion accessory for young women.</b>\n",
    "\n",
    "<b>The second element need to be considered is race.</b> America is a big melting pot where immigrants and people from all over the world live and share thoughts. Guess should invite influencers from different culture and races because the audience is much easier convinced by people are similar to them. Those influencers<b> age should be around 18-34</b> because our target customers are aged from 18-34.\n",
    "\n",
    "<b>The next should be considered</b> is how many followers they have. This depends on how much promotion budget they have, and what kind of their specific promotion strategy is.   \n",
    "\n",
    "<b>As for the location they live</b>, it is not very important as long as she is mostly active in the US because the Internet removes most the geography barriers for spreading infromation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Get the ranking list in fashion area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscrapping\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# for regurlar expressions\n",
    "import re\n",
    "\n",
    "# image display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_User_Page( username ):\n",
    "    # specify a header (if this script returns a ConnectionError exception, just change the name in the header)\n",
    "    headers = {'User-Agent': 'Catarina\\'s_request'}\n",
    "\n",
    "    username = username.replace(\" \", \"%20\")\n",
    "    # get the HTML page that contains the results of our search for the specified product\n",
    "    # you need to combine the url to make quesries on TESCO together with the product that you are searching for\n",
    "    link = \"https://www.instagram.com/\"+username+\"/\" \n",
    "\n",
    "    # connect to server. If the server returns a code different from 200, it means there was a connection error\n",
    "    # and it was not possible to connect to the server\n",
    "    response = requests.get( link, headers = headers )\n",
    "    if response.status_code != 200:\n",
    "        raise ConnectionError\n",
    "\n",
    "    # creates a parse tree that can be used to extract contents from HTML documents, which can be used for web scraping\n",
    "    soup = BeautifulSoup( response.content, 'html.parser')\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Top_Influencers_Page( ):\n",
    "    # specify a header (if this script returns a ConnectionError exception, just change the name in the header)\n",
    "    headers = {'User-Agent': 'Catarina\\'s_request'}\n",
    "\n",
    "    \n",
    "    # get the HTML page that contains the results of our search for the specified product\n",
    "    # you need to combine the url to make quesries on TESCO together with the product that you are searching for\n",
    "    link = \"https://izea.com/2018/03/05/top-fashion-instagram-influencers/\" \n",
    "\n",
    "    # connect to server. If the server returns a code different from 200, it means there was a connection error\n",
    "    # and it was not possible to connect to the server\n",
    "    response = requests.get( link, headers = headers )\n",
    "    if response.status_code != 200:\n",
    "        raise ConnectionError\n",
    "\n",
    "    # creates a parse tree that can be used to extract contents from HTML documents, which can be used for web scraping\n",
    "    soup = BeautifulSoup( response.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top = get_Top_Influencers_Page( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_All_Influencers_soup( soup):\n",
    "    Influencers_soup = soup.findAll('div', {'class' : 'wpb_text_column wpb_content_element' } )\n",
    "    return Influencers_soup\n",
    "Influencers_soup = get_All_Influencers_soup(Top)\n",
    "def get_All_Influencers_link_soup( soup):\n",
    "    Influencers_link_soup = soup.findAll('div', {'class' : 'img-with-aniamtion-wrap' } )\n",
    "    return Influencers_link_soup\n",
    "Influencers_link_soup = get_All_Influencers_link_soup(Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influencer_name( soup_elem  ):\n",
    "    name = soup_elem.div.h4.text\n",
    "    return name\n",
    "\n",
    "def get_influencer_intro( soup_elem ):\n",
    "    intro = soup_elem.div.p.text\n",
    "    return intro\n",
    "\n",
    "def get_influencer_ins_link( soup_elem ):\n",
    "    link = soup_elem.div.a['href']\n",
    "    return link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names=[]\n",
    "links=[]\n",
    "intros=[]\n",
    "for i in range(1,25):\n",
    "    \n",
    "    influencer_soup = Influencers_soup[i]\n",
    "    name =get_influencer_name(influencer_soup)\n",
    "    names.append(name)\n",
    "    intro = get_influencer_intro(influencer_soup)\n",
    "    intros.append(intro)\n",
    "    link=get_influencer_ins_link(Influencers_link_soup[i-1])\n",
    "    links.append(link)\n",
    "    print(names[i-1])\n",
    "    print(links[i-1])\n",
    "    print(intro+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we got the name of these influencers and their Instagram with brief introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get specific Influencers information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we get the top influencers ranking information. We need to know how many followers they have, their Instagram names, and how many posts they have by using urls we got from the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import re\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display style\n",
    "def HTML_display_style():\n",
    "    css = HTML(\"\"\"\n",
    "<style>\n",
    "    .box {\n",
    "        background-color: white;\n",
    "        width: calc(50% - 44px);\n",
    "        height: 250px;\n",
    "        margin: 5px;\n",
    "        padding: 10px;\n",
    "        overflow: hidden;\n",
    "        float:left;\n",
    "        clear: none;\n",
    "    }\n",
    "    \n",
    "</style>\n",
    "\"\"\")\n",
    "    return css\n",
    "\n",
    "def append_info_to_view(url,Vlist):\n",
    "    _HTML = ''\n",
    "    _HTML += '<div class=\"box\">'\n",
    "    _HTML += '<img src=\"'+url+'\" width=100 heigth=100 />'\n",
    "    _HTML += '<h4>'+Vlist['User']+'</h4>'\n",
    "    _HTML += '<p> has <strong>'+Vlist[\"Followers\"]+'  </strong>followers.</p>'\n",
    "    _HTML += '<p> has <strong>'+Vlist[\"Posts\"]+'  </strong>posts.</p></div>'\n",
    "    return _HTML\n",
    "\n",
    "#get the information of user\n",
    "def getinfo(url,display_html):\n",
    "    \n",
    "    html = urllib.request.urlopen(url).read()\n",
    "   \n",
    "    string=str(html,'utf-8')\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', string)\n",
    "    data = soup.find_all('meta', attrs={'property': 'og:description'\n",
    "                             })\n",
    "    text = data[0].get('content').split()\n",
    "    user = '%s %s %s' % (text[-3], text[-2], text[-1])\n",
    "    followers = text[0]\n",
    "    following = text[2]\n",
    "    posts = text[4]\n",
    "    info={}\n",
    "    info[\"User\"] = user\n",
    "    info[\"Followers\"] = followers\n",
    "    info[\"Following\"] = following\n",
    "    info[\"Posts\"] = posts\n",
    "    print(info[\"User\"])\n",
    "    display_html+=append_info_to_view(urls[75],info)\n",
    "    return display_html\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate HTML page for disply\n",
    "Html=''\n",
    "print(\"Getting information....\")\n",
    "for i in range(24):\n",
    "    url = links[i]\n",
    "    info = getinfo(url,Html)\n",
    "    Html = info\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show the influencers information\n",
    "css= HTML_display_style()\n",
    "display(css,HTML(Html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information we collect, we can know<b> Chiara Ferragni is the biggest influencers in fashion</b>. She has 16.5m followers. She's a millennial fashion and lifestyle influencer who became famous through her blog and later Instagram. In the early age, she also had model experience of Guess in November 2013. So, she should be the perfect person for the leading influencer in this event. For other small influencers, we choose <b>Danielle Bernstein, 임도희 and Gabi Gregg.</b> They represent three general racial classifications of humans Caucasoid, Mongoloid and Negroid. They all under 30 years old. At the same time, the total number of fans will definitely create a great buzz on the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Digital Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traditional way of marketing brands, products and services make use of either indirect or direct methods of reaching out to targeted customers. These methods are clear-cut and very straightforward – you just need to invest money, perform a set of actions, and get results. The business and marketing landscape have drastically changed in recent years however. Traditional methods that were effective before may not be as effective in this current market powered by the complexities – and the vast wealth of opportunities – by the Internet.  In our opinions, the best digital channel for promotion is the combination of different channels like <b>video, social media, and search engine</b> because these are young people used most in daily life. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Video Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of brands that use video content marketing strategy has increased. Currently, 87% of online content such as blogs, articles and images is in the form of a video. According to Cisco, by 2017, the video will account for 69% of all consumer internet traffic.[5] It is essential to know which video platform people used mostly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Top_Video_Page( ):\n",
    "    # specify a header (if this script returns a ConnectionError exception, just change the name in the header)\n",
    "    headers = {'User-Agent': 'Catarina\\'s_request'}\n",
    "\n",
    "    \n",
    "    # get the HTML page that contains the results of our search for the specified product\n",
    "    # you need to combine the url to make quesries on TESCO together with the product that you are searching for\n",
    "    link = \"http://www.ebizmba.com/articles/video-websites\" \n",
    "\n",
    "    # connect to server. If the server returns a code different from 200, it means there was a connection error\n",
    "    # and it was not possible to connect to the server\n",
    "    response = requests.get( link, headers = headers )\n",
    "    if response.status_code != 200:\n",
    "        raise ConnectionError\n",
    "\n",
    "    # creates a parse tree that can be used to extract contents from HTML documents, which can be used for web scraping\n",
    "    soup = BeautifulSoup( response.content, 'html.parser')\n",
    "    return soup\n",
    "def get_All_TOP_soup( soup):\n",
    "    Top_soup = soup.findAll('div', {'class' : 'module-content' } )\n",
    "    return Top_soup\n",
    "\n",
    "\n",
    "def append_video_platform_to_view(url,Vlist):\n",
    "    _HTML = ''\n",
    "    _HTML += '<div class=\"box\">'\n",
    "    _HTML += '<img src=\"'+url+'\" width=100 heigth=100 />'\n",
    "    _HTML += '<h4>'+Vlist.a.text+'</h4>'\n",
    "    _HTML += '<p> has <strong>'+Vlist.span.strong.text+'  </strong>Estimated Unique Monthly Visitors.</p></div>'\n",
    "    return _HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TOP_soup = get_Top_Video_Page()\n",
    "Top_list = get_All_TOP_soup(TOP_soup)\n",
    "Video_Plartform_list = Top_list[0].findAll('p', { })\n",
    "display_html=''\n",
    "for i in range(3,18):\n",
    "    img = Video_Plartform_list[i].a.img['src']\n",
    "    display_html+=append_video_platform_to_view(img,Video_Plartform_list[i])\n",
    "\n",
    "display(css,HTML(display_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list, we can know<b> YouTube</b> is in the first place, and they have nearly eight times than the second one. SO, we only consider YouTube as the only video promotion channel. \n",
    "<img src='Youtube.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Social Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media is definitely one of the most phenomenal thing to happen in the digital arena that business owners and digital marketers can leverage on to create brand awareness for their products and services. Through Social Media Marketing (SMM), digital marketers can reach out to highly targeted potential customers through direct and person-to-person engagement.[3]\n",
    "\n",
    "The first thing we need to know is which social media used most in the US. Then choose the top platform to promote Guess watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Get the ranking list</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for file and index column\n",
    "file = 'Social_Media_Ranking.csv' #see above\n",
    "colname = 'Social Media' #open the csv and have a look\n",
    "\n",
    "# Read in the percent of gdp data\n",
    "SocialMediaList = pandas.read_csv(file, index_col= colname)\n",
    "print(SocialMediaList.shape)\n",
    "SocialMediaList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "filter_stand =['Monthly users']\n",
    "#Mlist = SocialMediaList.filter(filter_stand, axis=1)\n",
    "#Mlist\n",
    "Mlist = SocialMediaList.loc['Facebook':'Group me','Monthly users']\n",
    "#Setup the data\n",
    "\n",
    "x = ['Facebook',\n",
    "'Instagram',\n",
    "'Facebook Messenger',\n",
    "'Twitter',\n",
    "'Pinterest',\n",
    "'Snapchat',\n",
    "'Reddit',\n",
    "'WhatsApp',\n",
    "'Tumblr',\n",
    "'Facebook Groups',\n",
    "'Google Hangouts',\n",
    "'Messenger by Google',\n",
    "'Group me'\n",
    "]\n",
    "colours = ['red','green','pink','yellow','blue','black','purple']\n",
    "#Plot the data\n",
    "fig = plt.figure(dpi=128,figsize=(10,6))\n",
    "plt.bar(x,Mlist, color=colours)\n",
    "\n",
    "#Lable the chart\n",
    "plt.ylabel('Monthly Users million')\n",
    "plt.xlabel('Social media')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Social media users ranking in US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization, we know the top 3 social media platforms are Facebook, Instagram, Facebook Messenger. After a little bit of research, we found these three platforms all belong to Facebook. Facebook also provides ads platform for business.\n",
    "<img src='facebook.PNG' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all people using the Internet are familiar and are making use of search engines to look for anything there is they want to know or are searching for. In fact, up to 93% of online experiences happening to these people usually begin by using a search engine. People use search engines to look for information about a brand, product or services, and up to 59% of search engine users each month find a local business to satisfy a particular need. SEO involves several activities like keyword research, making use of both on-page and off-page optimization, linkable assets creation, organic link building and other related activities.[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for file and index column\n",
    "file = 'search_engine-US.csv' #see above\n",
    "colname = 'Search Engine' #open the csv and have a look\n",
    "\n",
    "# Read in the percent of gdp data\n",
    "SearchEngineList = pandas.read_csv(file, index_col= colname)\n",
    "print(SearchEngineList.shape)\n",
    "#filter_stand =['Market Share Perc.']\n",
    "#Mlist = SearchEngineList.filter(filter_stand, axis=1)\n",
    "#Mlist\n",
    "#SearchEngineList\n",
    "Elist =SearchEngineList.loc['Google':'Other']\n",
    "Elist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting and visualization\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "labels = ['Google', 'Bing', 'Yahoo!','Other']\n",
    "\n",
    "size = [87.01,6.54,5.29,1.16]\n",
    "# Set different colors\n",
    "colors = ['pink','green', 'grey', 'red','blue']\n",
    "\n",
    "plt.pie(size, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, Google is the most significant player in the search engine market. Moreover, they also provide an excellent advertisement promotion service, Google Ads. When you input information relate to about watch or Guess, Google will recommend shopping, promotion and event information that you may need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Ads (formerly Google AdWords and Google AdWords Express) is an online advertising solution that businesses use to promote their products and services on Google Search, YouTube, and other sites across the web. Google Ads also allows advertisers to choose specific goals for their ads, like driving phone calls or website visits. With a Google Ads account, advertisers can customize their budgets and targeting, and start or stop their ads at any time.[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peer Review\n",
    "<b>Aldo Joshua Karyono (n10306773) to Peng Zhang (n10322396):</b>\n",
    "I think it is a very thorough analysis. I really like on how you include the borough reputation for the safety reasons of the event. The only feedback I’d like to give is to state your assumptions so the readers would understand more on what you were thinking when you did this analysis. Apart from that, this is a solid work. Well done!!<br>\n",
    "<br>\n",
    "\n",
    "<b>Peng Zhang (n10322396) to Aldo Joshua Karyono (n10306773):</b>\n",
    "I love the approach that you have taken for the analysis, especially on your thought to link Guess watches with the fashion industry because I personally think that Guess watches are more like fashion-watches rather than the luxury watches like Rolex, Tissot, Seiko, etc. Finding a location that is popular for fashion is a smart move since it is understandable that Guess will invite fashion influencers. In general, the report is very easy and attractive for the audience to read. Great job, you can get that 7!<br>\n",
    "\n",
    "<b>Kai LI(n10322469) to Peng Zhang(n10322396):</b>\n",
    "I think your way of finding the channels for the launch is very good. Select after classify will be much more efficient. While I think you should add more details to your criteria of influencers choosing. That can improve the result of the choosing.\n",
    "\n",
    "<b>Peng Zhang(n10322396) to Kai Li(n10322469):</b>\n",
    "I like the way how you find influencers and assess them with the engagement percentage with fans standard. I think this a very important because this can make this influencer have more influence on her fans. Furthermore, your logic is also apparent. However, I hope you can add more guiding sentences in your notebook, and this will make the notebook more readable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://shop.guess.com/en/ourstory/\n",
    "2. https://guesswhatsupwithguess.blogspot.com/2009/03/3-target-markets.html\n",
    "3. https://digitalmarketingphilippines.com/how-to-choose-the-best-digital-marketing-channel-for-your-business/\n",
    "4. https://ads.google.com/intl/en_au/home/faq/\n",
    "5. https://www.brid.tv/not-getting-enough-views-videos-wrong/#more-624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
